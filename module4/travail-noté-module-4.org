#+LANGUAGE: fr
#+OPTIONS: title:nil toc:nil num:nil
#+LaTeX_HEADER: \usepackage{caption}
#+LaTeX_HEADER: \captionsetup[figure]{labelformat=empty}
#+LATEX_HEADER: \usepackage{parskip}
#+LATEX_HEADER: \setcounter{section}{1}

* Travail noté #4 : Construisez un modèle de langage

Un modèle de langage est un outil mathématique qui permet d'établir la
distribution statistique des mots : en présence (ou dans le contexte)
de certains mots, quel mot a tendance à suivre, et dans quelle
proportion des cas (liés. avec quelle probabilité). Un modèle de
langage n'est pas un objet abstrait qui décrit une réalité théorique :
il s'agit d'un modèle statistique entraîné sur des données
particulières. De la même manière qu'un modèle de prédiction de la
température pour la ville de Montréal est différent d'un modèle pour
la ville de Québec, un modèle de langage créé par exemple à partir des
données de 100 livres écrits au 19ième siècle, et un autre à partir de
100 livres écrits au 20ième siècles, seront deux modèles distincts, et
auront des propriétés statistiques très différentes.

Tout comme le modèle de classification du travail noté #2, il est
encore ici question de probabilité conditionnelle. Étant donné que
nous allons construire un modèle bigramme, il s'agit donc de la
probabilité d'un mot, étant donné le mot qui le précède (la barre
verticale dans l'équation signifie "étant donné", ou "en présence de",
ou "dans le contexte de") :

#+BEGIN_EXPORT latex
\[
\text{Prob(mot à prédire | mot qui précède)}}
\]
#+END_EXPORT

La tâche de notre modèle de classification pour les courriels était de
discriminer (répondre oui ou non à la question : est-ce un pourriel?)
tandis que la tâche de notre modèle bigramme sera ici de générer du
nouveau texte, une fois le modèle entraîné, en faisant de
l'échantillonnage. La génération de nouveau texte est ce qui permet à
ChatGPT de répondre à une question, ou de composer un poème.

** Entraînement du modèle

Voyons comment il est possible de calculer ces probabilités en
entraînant un modèle bigramme génératif sur un texte très simple.

Nous allons encore une fois utiliser le tableur [[https://sheets.google.com][Google Sheets]] au lieu
de Excel, car Google Sheets est plus accessible, et le langage de ses
formules est plus facile à gérer (celui d'Excel dépend de la langue et
des paramètres régionaux de votre système d'exploitation). Pour éviter
la confusion dans le contexte de ce travail, nous devons tout d'abord
nous assurer que la langue des fonctions et des paramètres régionaux
est l'anglais :

#+ATTR_LATEX: :width 1.0\textwidth :float nil
[[file:./images/tn4/sheets_params_langue.png]]

Assurez-vous ensuite que la "barre de formules" soit visible :

#+ATTR_LATEX: :width 1.0\textwidth :float nil
[[file:./images/tn4/sheets_visu_barre_formule.png]]

#+LATEX: \newpage

Copiez tout d'abord les mots de ce texte dans la colonne A d'une
nouvelle "feuille" Google Sheets, un mot par rangée :

#+BEGIN_EXPORT latex
\begin{verbatim}
le
chat
dort
le
chien
mange
le
chat
mange
une
souris
le
chien
dort
la
souris
court
la
souris
mange
le
fromage
le
chat
court
le
chien
voit
le
chat
le
chat
voit
la
souris
le
chien
court
\end{verbatim}
#+END_EXPORT

Dans la première cellule de la colonne B (donc B1), entrez cette formule :

#+BEGIN_EXPORT latex
\begin{verbatim}
=A2
\end{verbatim}
#+END_EXPORT

La colonne B devrait être étendue jusqu'à la cellule B37, en
double-cliquant sur le petit "+" qui apparaît quand votre curseur est
placé au-dessus du coin inférieur droit de la cellule B1 (il est
possible que Google Sheets offre de le faire pour vous,
automatiquement).

Dans la cellule C1, entrez maintenant cette formule :

#+BEGIN_EXPORT latex
\begin{verbatim}
=A1 & " " & B1
\end{verbatim}
#+END_EXPORT

Encore une fois, la colonne C doit s'étendre jusqu'à la cellule C37).
À ce stade, votre feuille devrait ressembler à ceci :

#+ATTR_LATEX: :width 0.8\textwidth :float nil
[[file:./images/tn4/sheets_3_first_cols.png]]

À ce stade, il devrait être clair pour vous que la colonne C contient
tous les bigrammes extraits du texte de la colonne A (la colonne B
n'est qu'un mécanisme pour les obtenir facilement).

Nous allons maintenant compter, dans la colonne D, le nombre de fois
où un bigramme particulier apparaît dans le texte de la colonne A (la
colonne D doit être étendue pour avoir le même nombre d'éléments que
la colonne C) :

#+BEGIN_EXPORT latex
\begin{verbatim}
=COUNTIF(C:C, C1)
\end{verbatim}
#+END_EXPORT

On constate par exemple que le bigramme "le chien" apparaît 4 fois,
tandis que le bigramme "fromage le", apparaît seulement une fois.

Dans la colonne E, nous allons maintenant calculer les paramètres de
notre modèle, soit la probabilité d'un mot, étant donné le mot qui le
précède :

#+BEGIN_EXPORT latex
\[
\text{Prob(mot de la col B | mot de la col A)}} =
\frac{
  \#(\text{mots A et B})
}{
  \#(\text{mot A})
}
\]
#+END_EXPORT

Pour ce faire, entrez dans la cellule E1 (la formule est un peu
complexifiée par le fait qu'on veut considérer tous les mots de la
colonne A sauf le dernier, car sa présence fausserait légèrement les
probabilités) :

#+BEGIN_EXPORT latex
\begin{verbatim}
=D1 / COUNTIF(A$1:INDEX(A:A, COUNTA(A:A)-1), A1)
\end{verbatim}
#+END_EXPORT

La probabilité d'un mot étant donné le mot qui le précède est donc
simplement le nombre de fois où ce bigramme particulier apparaît dans
le texte, divisée par le nombre de fois où le premier mot du bigramme
apparaît. Étant donné que cette valeur est une probabilité, elle doit
nécessairement être contenue entre 0 et 1.

Dans la colonne F nous allons filtrer la colonne C (tous les
bigrammes) pour ne retenir que les bigrammes uniques :

#+BEGIN_EXPORT latex
\begin{verbatim}
=SORT(UNIQUE(C:C))
\end{verbatim}
#+END_EXPORT

Nous devons séparer les mots des bigrammes uniques, les premiers mots
dans la colonne G :

#+BEGIN_EXPORT latex
\begin{verbatim}
=INDEX(SPLIT(F1, " "), 1)
\end{verbatim}
#+END_EXPORT

suivis des deuxièmes mots (des bigrammes uniques de la colonne F) dans
la colonne H :

#+BEGIN_EXPORT latex
\begin{verbatim}
=INDEX(SPLIT(F1, " "), 2)
\end{verbatim}
#+END_EXPORT

Et dans la colonne I nous allons ajouter les probabilités
correspondantes (provenant de la colonne E):

#+BEGIN_EXPORT latex
\begin{verbatim}
=INDEX(E:E, MATCH(F1, C:C, 0))
\end{verbatim}
#+END_EXPORT

On peut maintenant constater que le mot "souris" suit nécessairement
(avec une probabilité de 1) le mot "la", tandis que le mot "le" peut
être suivi des mots "chat", "chien" et "fromage" avec des
probabilités de 0.5, 0.4 et 0.1, respectivement.

À ce stade, votre feuille devrait ressembler à ceci :

#+ATTR_LATEX: :width 1.0\textwidth :float nil
[[file:./images/tn4/sheets_model_complete.png]]

#+LATEX: \newpage

** Utilisation du modèle (inférence)

Maintenant que notre modèle de langage est "entraîné" (c'est-à-dire
que les probabilités pour les différents bigrammes, les paramètres
donc, sont calculées), on peut l'utiliser pour générer un nouveau
texte.

Pour démarrer le mécanisme de génération, on peut entrer un premier mot dans
la cellule J1, par exemple le mot "le".

Ensuite, la génération peut être effectuée avec cette formule plus
complexe, à partir de la cellule K1 si vous désirez que les mots
soient générés à la verticale, ou J2 si vous désirez qu'ils le soient
à l'horizontale (attention étant donné que cette formule contient
plusieurs lignes elle doit être entrée dans l'espace de la formule, en
haut des colonnes):

#+BEGIN_EXPORT latex
\begin{verbatim}
=LET(
  next_word_mask, ARRAYFORMULA($G:$G = J1),
  next_words, FILTER($H:$H, next_word_mask),
  probs, FILTER($I:$I, next_word_mask),
  probs_cumul, SCAN(0, probs, LAMBDA(a, b, a + b)),
  sampled_word_idx, MATCH(RAND(), {0; probs_cumul}, 1),
  INDEX(next_words, sampled_word_idx)
)
\end{verbatim}
#+END_EXPORT

#+ATTR_LATEX: :width 1.0\textwidth :float nil
[[file:./images/tn4/sheets_generate.png]]

Cette formule détermine tout d'abord quels sont les prochains mots
possibles (suivant le mot "le", dans ce cas particulier), ainsi que
leur probabilité associée. Elle choisit ensuite le mot suivant en
choisissant un nombre aléatoire qui est utilisé en tant qu'index dans
la liste des probabilités cumulatives (cette procédure est appelée
échantillonnage).

Si votre deuxième mot généré se trouve dans la cellule K2, vous pouvez
continuer la génération en glissant la cellule vers la droite. Si votre
deuxième mot se trouve plutôt dans la cellule J2, vous pouvez poursuivre
la génération en glissant la cellule J2 vers le bas.

** Questions
